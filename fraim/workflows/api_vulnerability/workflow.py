# SPDX-License-Identifier: MIT
# Copyright (c) 2025 Resourcely Inc.

"""
API Vulnerability Assessment Workflow

Analyzes API interface discovery findings to identify OWASP API Security Top 10 2023 vulnerabilities.
This workflow operates on API interface findings rather than code chunks directly, using the findings
to guide targeted security analysis of the codebase.
"""

import json
from typing import Any, Dict, List, Optional

from fraim.config import Config
from fraim.core.llms.litellm import LiteLLM
from fraim.core.steps.llm import LLMStep
from fraim.core.workflows import Workflow
from fraim.workflows.registry import workflow
from fraim.workflows.utils import write_json_output

from .steps import create_vulnerability_assessment_step
from .types import (
    ApiVulnerabilityInput,
    VulnerabilityAssessmentAgentInput,
    VulnerabilityAssessmentResult,
)
from .utils import create_security_summary, deduplicate_security_controls, deduplicate_vulnerabilities


@workflow("api_vulnerability")
class ApiVulnerabilityWorkflow(Workflow[ApiVulnerabilityInput, Dict[str, Any]]):
    """
    Analyzes API interface discovery findings to identify OWASP API Security Top 10 2023 vulnerabilities.

    This workflow takes the output from the api_interface_discovery workflow and performs targeted
    security analysis to identify potential vulnerabilities in the discovered API interfaces.

    Key Features:
    - Maps API interface findings to OWASP API Security Top 10 2023 categories
    - Uses TreeSitter tools to analyze code patterns for security vulnerabilities
    - Identifies missing security controls and potential attack vectors
    - Provides remediation advice and risk assessments
    - Operates on findings rather than code chunks for efficient analysis
    """

    def __init__(self, config: Config, *args: Any, **kwargs: Any) -> None:
        super().__init__(config, *args, **kwargs)

        # Store config for later use
        self.config = config

        # Initialize LLM
        self.llm = LiteLLM.from_config(self.config)

        # Keep step as lazy since it depends on project setup for tools
        self._vulnerability_assessment_step: Optional[LLMStep[VulnerabilityAssessmentAgentInput,
                                                              VulnerabilityAssessmentResult]] = None

    @property
    def vulnerability_assessment_step(self) -> LLMStep[VulnerabilityAssessmentAgentInput, VulnerabilityAssessmentResult]:
        """Lazily initialize the vulnerability assessment step with tools."""
        if self._vulnerability_assessment_step is None:
            self._vulnerability_assessment_step = create_vulnerability_assessment_step(
                self.llm, self.config, self._project_path
            )
        return self._vulnerability_assessment_step

    def _validate_api_interface_findings(self, findings_json: str) -> Dict[str, Any]:
        """Validate and parse the API interface findings JSON."""
        try:
            findings = json.loads(findings_json)

            # Validate that we have the expected structure
            required_fields = ["rest_endpoints", "graphql_schema",
                               "websocket_connections", "data_models"]
            for field in required_fields:
                if field not in findings:
                    self.config.logger.warning(
                        f"Missing required field '{field}' in API interface findings")
                    findings[field] = []

            return findings
        except json.JSONDecodeError as e:
            raise ValueError(
                f"Invalid JSON in API interface findings: {str(e)}")

    def _print_security_summary(self, final_result: Dict[str, Any]) -> None:
        """Print a concise summary of security findings."""
        security_summary = final_result.get("security_summary", {})

        total_vulns = security_summary.get("total_vulnerabilities", 0)
        critical = security_summary.get("critical_count", 0)
        high = security_summary.get("high_count", 0)
        medium = security_summary.get("medium_count", 0)
        low = security_summary.get("low_count", 0)
        posture = security_summary.get(
            "overall_security_posture", "unknown").upper()

        self.config.logger.info(
            f"Security Assessment Summary: {total_vulns} total vulnerabilities "
            f"(Critical: {critical}, High: {high}, Medium: {medium}, Low: {low}) "
            f"- Security Posture: {posture}"
        )

    async def workflow(self, input: ApiVulnerabilityInput) -> Dict[str, Any]:
        """Main API Vulnerability Assessment workflow."""
        try:
            self.config.logger.info(
                "Starting API Vulnerability Assessment workflow")

            # Store project path for tool initialization
            self._project_path = input.project_path

            # 1. Validate API interface findings
            api_findings = self._validate_api_interface_findings(
                input.api_interface_findings)

            # Count total API interfaces found
            total_endpoints = (
                len(api_findings.get("rest_endpoints", [])) +
                len(api_findings.get("graphql_schema", [])) +
                len(api_findings.get("websocket_connections", []))
            )

            if total_endpoints == 0:
                self.config.logger.warning(
                    "No API interfaces found in the provided findings")
                return {
                    "vulnerabilities": [],
                    "security_controls": [],
                    "security_summary": {
                        "total_vulnerabilities": 0,
                        "critical_count": 0,
                        "high_count": 0,
                        "medium_count": 0,
                        "low_count": 0,
                        "overall_security_posture": "unknown",
                        "confidence_score": 0.0,
                    },
                    "analysis_summary": "No API interfaces found for vulnerability assessment",
                }

            self.config.logger.info(
                f"Analyzing {total_endpoints} API interfaces for security vulnerabilities")

            # 2. Run vulnerability assessment
            assessment_input = VulnerabilityAssessmentAgentInput(
                api_interface_findings=input.api_interface_findings,
                project_path=input.project_path,
                config=self.config,
            )

            assessment_result = await self.vulnerability_assessment_step.run(assessment_input)

            # 3. Deduplicate findings
            unique_vulnerabilities = deduplicate_vulnerabilities(
                assessment_result.vulnerabilities)
            unique_security_controls = deduplicate_security_controls(
                assessment_result.security_controls_present)

            # 4. Create security summary
            security_summary = create_security_summary(unique_vulnerabilities)

            # 5. Build final result
            final_result = {
                "vulnerabilities": [vuln.model_dump() for vuln in unique_vulnerabilities],
                "security_controls": [control.model_dump() for control in unique_security_controls],
                "security_summary": security_summary,
                "analysis_summary": f"Analyzed {total_endpoints} API interfaces. Found {len(unique_vulnerabilities)} security issues.",
                "api_interfaces_analyzed": total_endpoints,
            }

            self.config.logger.info(
                f"API Vulnerability Assessment completed. "
                f"Analyzed {total_endpoints} API interfaces. "
                f"Found {len(unique_vulnerabilities)} security issues. "
                f"Security Posture: {security_summary['overall_security_posture'].upper()}"
            )

            # 6. Write output file if output_dir is configured
            write_json_output(
                results=final_result, workflow_name="api_vulnerability", config=self.config)

            # 7. Print detailed security summary
            self._print_security_summary(final_result)

            return final_result

        except Exception as e:
            self.config.logger.error(
                f"Error during API vulnerability assessment: {str(e)}")
            raise e
